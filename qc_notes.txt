QUALITY CONTROL NOTES: JOHANSEN COINTEGRATION AND VAR ANALYSIS

PROMPT GOAL:

Conduct comprehensive cointegration and vector autoregression analysis on three technology stock price series (AMAZON, GOOGLE, META) using exact date intersection methodology with daily log returns. Apply Johansen cointegration test with Schwarz criterion lag selection and trace test rank determination at five percent significance, normalizing the first cointegrating vector on META when cointegration exists. Estimate vector autoregression model on returns with Akaike criterion lag selection, generate sixty-day out-of-sample one-step-ahead forecasts, and compute average root mean squared error across all three series. Perform supplementary analyses including sixty-day rolling correlation over five-year window, pairwise Granger causality testing for all directed pairs, ten-day impulse response quantification for META to one percent orthogonalized GOOGLE shock using Cholesky ordering, and Ornstein-Uhlenbeck mean reversion half-life estimation from the cointegrating spread. Deliver seven scalar outputs (cointegration rank, VAR lag order, average RMSE, maximum correlation, Granger pair count, peak impulse magnitude, half-life) plus risk policy summary with detailed discussion.

STEP-BY-STEP SOLUTION:

Step 1: Load the three CSV files containing AMAZON, GOOGLE, and META daily stock price data and extract Date and Adj Close columns from each dataset. Perform inner join merge operations to identify the exact intersection of trading days present across all three files, ensuring only dates common to all three datasets are retained. Sort the merged data chronologically by date to maintain proper temporal ordering. This produces 3,385 common trading days spanning from May 18, 2012 to November 3, 2025, establishing the unified sample period for all subsequent analysis steps.

Step 2: Calculate natural logarithm of Adj Close prices for all three series to obtain log price vectors suitable for cointegration testing. Compute daily log returns as the first difference of log prices, which mechanically removes exactly one observation from the beginning of each return series due to the differencing operation. The log return transformation ensures that percentage changes are symmetric and approximately normally distributed for statistical inference. This yields 3,384 log return observations while preserving the original 3,385 log price observations for cointegration analysis.

Step 3: Select optimal lag order for the Johansen cointegration test by fitting unrestricted vector autoregression models to the log price levels over the candidate range of one through five lags. Compute Schwarz Bayesian Criterion for each lag specification and identify the lag order that minimizes this information criterion. The Schwarz criterion penalizes model complexity more heavily than alternative criteria, promoting parsimonious specifications. Optimal lag order is four for the VAR in levels, which corresponds to three lagged differences in the vector error correction model representation used by the Johansen procedure.

Step 4: Apply Johansen cointegration test to the three-dimensional log price vector using the selected lag order with deterministic specification that includes a constant term in the cointegrating relation but not in the short-run dynamics. This specification allows for non-zero mean in the stationary cointegrating combinations while maintaining the random walk structure of individual price series under the null hypothesis of no cointegration. Extract trace statistics and corresponding five percent critical values for sequential hypothesis testing of cointegration rank. The test generates three trace statistics corresponding to null hypotheses of rank less than or equal to zero, one, and two respectively.

Step 5: Determine cointegration rank by sequentially comparing trace statistics against five percent critical values, rejecting the null hypothesis when the trace statistic exceeds the critical threshold. The trace statistic of 435.35 for rank zero exceeds critical value 29.80, the trace statistic of 219.10 for rank one exceeds critical value 15.49, and the trace statistic of 74.63 for rank two exceeds critical value 3.84, leading to triple rejection. This establishes cointegration rank r equals three, indicating all three log price series are individually stationary without common stochastic trends. Normalize the first cointegrating vector on META by dividing all coefficients by the META coefficient, yielding normalized weights of negative 1.2075 for GOOGLE, positive 0.1670 for AMAZON, and 1.0000 for META.

Step 6: Fit vector autoregression models to the return series over lag orders one through five with intercept terms included to capture non-zero mean returns. Compute Akaike Information Criterion for each specification and select the lag order minimizing this criterion. The Akaike criterion balances goodness of fit against model parsimony with lighter penalty than Schwarz criterion, often selecting slightly longer lag lengths. Optimal VAR lag order is five, requiring five lagged return observations for each of the three variables plus intercept in each equation.

Step 7: Estimate the five-lag vector autoregression on the training sample excluding the most recent sixty trading days, fitting three equations with intercepts and fifteen lagged return regressors each. Verify model stability by computing companion matrix eigenvalues and confirming all eigenvalues have modulus strictly less than one. The maximum eigenvalue modulus is 0.728, well inside the unit circle, establishing that the estimated system is stable with mean-reverting dynamics. Stable VAR ensures forecasts converge to unconditional means and impulse responses decay to zero over time.

Step 8: Generate one-step-ahead forecasts for each of the sixty test period trading days using expanding window methodology that incorporates actual realized returns as they become available. For each forecast date, use all available historical data through the previous day with the five-lag structure to predict the next day returns. Compute forecast errors as actual minus predicted returns for each asset on each day. Calculate root mean squared error separately for GOOGLE (0.3162), AMAZON (0.3166), and META (0.3540), then average these three values to obtain overall RMSE of 0.3289.

Step 9: Identify the most recent five full calendar years within the common sample by requiring both January and December observations present for each year, yielding calendar years 2020 through 2024 as the five-year window. Compute sixty-day rolling Pearson correlations for all three asset pairs (GOOGLE-AMAZON, GOOGLE-META, AMAZON-META) across this five-year subset containing 1,258 trading days. Extract the maximum correlation value attained by any pair at any point in the rolling window including all window endpoints. The GOOGLE-AMAZON pair achieves maximum rolling correlation of 0.8369, exceeding the maxima of 0.8183 for GOOGLE-META and 0.7765 for AMAZON-META.

Step 10: Execute pairwise Granger causality F-tests for all six ordered pairs (GOOGLE to AMAZON, GOOGLE to META, AMAZON to GOOGLE, AMAZON to META, META to GOOGLE, META to AMAZON) using lag specifications from one through five at five percent significance level. For each directed pair, test whether lagged values of the causing variable provide statistically significant predictive power for the effect variable beyond the effect variable's own lags. Count a direction as significant if any single lag within the one-through-five range produces an F-test p-value below 0.05. Four directed pairs show significant Granger causality: GOOGLE causes AMAZON (p equals 0.0328), GOOGLE causes META (p equals 0.0169), AMAZON causes GOOGLE (p equals 0.0050), and AMAZON causes META (p equals 0.0000).

Step 11: Produce ten-period impulse response function from the fitted five-lag VAR using Cholesky orthogonalization with variable ordering GOOGLE first, AMAZON second, META third to identify contemporaneous structural relationships. Extract the response trajectory of META returns to an orthogonalized shock in GOOGLE across horizons zero through nine. Scale the one-standard-deviation orthogonalized response by multiplying by 0.01 to reflect a one percent shock magnitude in return space. The contemporaneous response at horizon zero is 0.1337 percent, representing the absolute peak magnitude across all ten periods, with subsequent responses decaying in oscillating fashion.

Step 12: Construct the cointegrating spread as the linear combination of log prices using the META-normalized first eigenvector with coefficients negative 1.2075 for GOOGLE, positive 0.1670 for AMAZON, and 1.0000 for META. Estimate discrete-time Ornstein-Uhlenbeck model by regressing spread changes on lagged spread levels using ordinary least squares across the full in-sample period. The estimated autoregressive coefficient is 0.7202, implying mean reversion speed parameter theta equals 0.2798 per trading day from the relationship theta equals negative log of the autoregressive coefficient. Calculate half-life as natural logarithm of two divided by theta, yielding 2.48 trading days as the expected time for half of any equilibrium deviation to dissipate.

Step 13: Formulate risk policy constraining all model outputs to historical variance bounds with categorical prohibition of leverage on cointegration trades, recognizing that full rank cointegration represents regime-specific behavior unlikely to persist indefinitely. The policy acknowledges that stationary log prices over this particular sample period constitute an unusual empirical finding for equity securities that typically exhibit unit root behavior. Position sizing restricted to historical volatility levels prevents catastrophic losses when mean reversion dynamics eventually break down during regime transitions. Conservative constraints embedded directly in the modeling framework provide operational guardrails without requiring subjective judgment about future validation milestones or market regime identification.
